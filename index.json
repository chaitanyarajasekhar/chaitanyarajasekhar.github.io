[{"authors":["admin"],"categories":null,"content":"I am a Computer Engineering PhD student at Arizona State University under the guidance of Prof. Heni Ben Amor. I joined Interactive Robotics Lab in January of 2019 after completing my Master of Science degree in Electrical and Computer Engineering at the University of Florida. I have previously worked with prof. Kamran Mohseni, on a depth controller design for underwater vehicles and model reduction projects at the University of Florida. My research interests encompasses the intersection of Reinforcement Learning, Controls, Robotics, Model Learning, and Multi-agent Systems. Currently, I am working on an Intel-funded project on Decentralized Multi-agent driving based on Probabilistic Reinforcement Learning and Model Predictive Control. As a part of the project, I am developing a hardware platform called “sundevil-f1/10car” for the multi-agent research. Check out the blog for more information on the platform and project on Sundevil-F1/10Car.\n","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":-62135596800,"objectID":"598b63dd58b43bce02403646f240cd3c","permalink":"https://chaitanyarajasekhar.github.io/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"author","summary":"I am a Computer Engineering PhD student at Arizona State University under the guidance of Prof. Heni Ben Amor. I joined Interactive Robotics Lab in January of 2019 after completing my Master of Science degree in Electrical and Computer Engineering at the University of Florida. I have previously worked with prof. Kamran Mohseni, on a depth controller design for underwater vehicles and model reduction projects at the University of Florida. My research interests encompasses the intersection of Reinforcement Learning, Controls, Robotics, Model Learning, and Multi-agent Systems.","tags":null,"title":"Chaitanya Rajasekhar","type":"author"},{"authors":["Chaitanya Rajasekhar"],"categories":null,"content":"Please click on the image below for the video. In the video I have used BLDC_tool from veddar, to set constant steering angle and throttle values to make the car move in circles.\n\n","date":1552114800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1552114800,"objectID":"3689d1ed530f2189c34ff2b2b7f0f6f3","permalink":"https://chaitanyarajasekhar.github.io/post/updated_car/","publishdate":"2019-03-09T00:00:00-07:00","relpermalink":"/post/updated_car/","section":"post","summary":"Demo with car moving in circles","tags":["RC-Car"],"title":"Video-demo","type":"post"},{"authors":["Chaitanya Rajasekhar"],"categories":null,"content":"We at Interactive Robotics Lab at ASU are working on RC-car based robotics platform for multi-agent research. We call it f1/10car which stands for Fast - 1/10th (scale) - Cooperative - Autonomous - Robot. This project is funded by Intel. It is based on Traxxas Slash 4x4 platinum RC-car, and inspired by the mit-racecar design.\nIn this post, I will be briefly describing the electronics hardware and software we are using in the car. For our application, we need an embedded GPU-processor which can handle computer vision and reinforcement learning networks, so we choose the Nvidia\u0026rsquo;s Jetson platform\u0026rsquo;s TX2 development kit which is economical when compared to their new Xavier board and can handle GPU computing.\nFor perception, we are using a ZED depth camera from stereo labs, which is a little older than the recent Intel\u0026rsquo;s realsense 435i depth camera. In terms of specifications, realsense is much smaller and has a better depth sensing in indoors due to its active IR stereo, but it has very less compatibility with cuda and getting it to work with the TX2 is a little difficult. For convenience, we moved forward with the zed camera. Since we are only using one forward camera, for localization and a 360-degree view we needed a single beam lidar. Slamtec Rplidar A3 is perfect in size and has ros compatibility within our budget. We also have a Velodyne VLP-16 lidar in the lab which I think is power hungry, heavy, and overkill for this project.\nFor state and pose estimation, we are using razor 9DOF imu.\nLastly, Slash 4x4 already comes with an Electronic Speed Controller (ESC) which has some limitations like the lowest speed it can work with 5 miles/hr which is not suitable for our application. This made us to replace it with VESC which is opensource and has ros support. VESC in the picture below is based on 4.12 hardware firmware.\nIn the later posts, I will be talking more about the design with some tutorials.\n","date":1551078000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1551942000,"objectID":"e91490de056ba6d6a1e7e17af6445617","permalink":"https://chaitanyarajasekhar.github.io/post/rc_car_getting_started/","publishdate":"2019-02-25T00:00:00-07:00","relpermalink":"/post/rc_car_getting_started/","section":"post","summary":"Introducing 1/10th scale RC-car platform for multi-agent robotics research","tags":["RC-Car"],"title":"sundevil-f1/10car","type":"post"},{"authors":null,"categories":null,"content":"I am working on an intel funded project to study aggressive driving and tracking on the sundevil-f1/10car (RC-car) platform. The main goal of the project is to use a probabilistic reinforcement learning framework to learn to drive as close as to the obstacle or tracking object by avoiding collisions.\n","date":1547103600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1547103600,"objectID":"dc27de81ea43c94f13f69a45a3a22f6a","permalink":"https://chaitanyarajasekhar.github.io/project/multi-agent-aggressive-driving/","publishdate":"2019-01-10T00:00:00-07:00","relpermalink":"/project/multi-agent-aggressive-driving/","section":"project","summary":"Learning of aggressive RC-car driving","tags":["Reinforcement Learning","Model Predictive Control","Multi-Agent Systems","Model Learning"],"title":"Multi-agent Aggressive Driving","type":"project"}]